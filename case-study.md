# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: я взял файлики со 100, 1К и 10К и 1M первых строк от целевого файла. Буду запускать программу и смотреть время работы на этих примерах. На начально этапе за конечное время отработали
только три первых:

На 100 строк: 0.0024728810003580293
На 1000 строк: 0.05411845200069365
На 10000 строк: 4.466623477999747

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за примерно 4 - 5 часов
с учетом ведения журнала.

Вот как я построил `feedback_loop`:
  1) Вынес тест в отдельный файл, чтобы в основном коде программы он не мешал
  2) В основной метод программы сделал подачу файла извне, так удобнее
  3) На первом этапе сделал два запускаемых файла run_benchmark.rb и run_prof.rb

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
  - ruby-prof профилировщик

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста
  ruby-prof
- как вы решили её оптимизировать
  ```
    sessions_by_users = sessions.group_by { |session| session['user_id'] }
  ```
  Если единожды сгруппировать сессии по пользователям, то не придется каждый раз бегать.

- как изменилась метрика
  На 100 строк: 0.002705422000872204
  На 1000 строк: 0.02647001100012858
  На 10000 строк: 0.3955349349998869
  На 100000 строк: 10.232019221000883

  При объеме данных от 100 строк программа работает в 10 раз быстрее. Стало возможным посмотреть
  результат для 100К строк. Для 1М по прежнему не дождался.

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

  Перестала, select вообще ушел.

### Моя находка №1
- какой отчёт показал главную точку роста
  ruby-prof через flat
- как вы решили её оптимизировать
  ```
    sessions_by_users = sessions.group_by { |session| session['user_id'] }
  ```
  Если единожды сгруппировать сессии по пользователям, то не придется каждый раз бегать.

- как изменилась метрика
  На 100 строк: 0.002705422000872204
  На 1000 строк: 0.02647001100012858
  На 10000 строк: 0.3955349349998869
  На 100000 строк: 10.232019221000883

  При объеме данных от 100 строк программа работает в 10 раз быстрее. Стало возможным посмотреть
  результат для 100К строк. Для 1М по прежнему не дождался.

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

  Перестала, select вообще ушел.

### Моя находка №2
- какой отчёт показал главную точку роста
  ruby-prof через callstack

  Отчет показал крайне неоптимальный рассчет кол-ва уникальных браузеров при методе all?.
  Примерно 25 процентов времени туда уходит.
- как вы решили её оптимизировать

  Его можно сильно упростить
  ```
    report['uniqueBrowsersCount'] = sessions.group_by { |a| a['browser'] }.size
  ```
- как изменилась метрика
  На 100 строк: 0.0022266249998210697
  На 1000 строк: 0.020008939000035753
  На 10000 строк: 0.2806640819999302
  На 100000 строк: 7.508185828999558

  На 100К строк скорость возросла примерно на 25 процентов.

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  Перестала.

### Моя находка №3
- какой отчёт показал главную точку роста
  ruby-prof через callstack

- как вы решили её оптимизировать

  Вынес в отдельный метод и оптимизировал накомпление пользователей и сессий
  ```
    def users_and_sessions(file_lines)
      users = []
      sessions = []
      file_lines.each do |line|
        users.push(parse_user(line)) if line.start_with?('user')
        sessions.push(parse_session(line)) if line.start_with?('session')
      end
      [users, sessions]
    end
  ```
- как изменилась метрика
  На 100 строк: 0.0021324789995560423
  На 1000 строк: 0.014970399000958423
  На 10000 строк: 0.14433964799900423
  На 100000 строк: 2.319276398000511

  На 100К строк прирост в 4 раза.
  Удалось дождаться метрики в 1М

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

  Перестала, более минорные теперь вышли вверх

### Моя находка №4
- какой отчёт показал главную точку роста
  ruby-prof через callstack

- как вы решили её оптимизировать

  Обнаружил, Date.parse, заменил на явное создание даты по формату

- как изменилась метрика
  На 100 строк: 0.0011813630007964093
  На 1000 строк: 0.009179262000543531
  На 10000 строк: 0.12648792999971192
  На 100000 строк: 1.9114379909988202
  На 1000000 строк: 70.34582342913812

  На 100К есть прирост, на 20 процентов. Кажется, что я нашел на самую большую точку роста.

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

  Перестала, более минорные теперь вышли вверх.

### Моя находка №5
- какой отчёт показал главную точку роста
  ruby-prof через callstack

- как вы решили её оптимизировать

  Обнаружил, что, когда собираем данные по пользователям, то много лишних раз бегаем по сессиям.
  Вынес всю беготню по сессиям в пользователя.

  ```
  def initialize(attributes:, sessions:)
    @attributes = attributes
    @sessions = sessions
    @dates = []
    @times = []
    @browsers = []
    sessions.each do |session|
      @dates.push(Date.strptime(session['date'], '%Y-%m-%d'))
      @browsers.push(session['browser'])
      @times.push(session['time'].to_i)
    end
  end
  ```

- как изменилась метрика
  На 100 строк: 0.001079875000868924
  На 1000 строк: 0.010886629999731667
  На 10000 строк: 0.12331333700058167
  На 100000 строк: 1.9798258279988659
  На 1000000 строк: 48.138456607997796

  На 100К прироста нет, но есть прирост на 1М.

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

  Перестала, более минорные теперь вышли вверх.

### Моя находка №6
- какой отчёт показал главную точку роста
  ruby-prof через callstack

- как вы решили её оптимизировать
  При сборке статистики не обязательно бегать 7 раз по списку пользователей, можно один раз

- как изменилась метрика
  На 100000 строк: 1.656587669000146
  На 1000000 строк: 45.155139178001264

  На 1М есть прирост, но не большой. Возможно, не угадал с главной точкой

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

  Перестала, более минорные теперь вышли вверх.

### Моя находка №7
- какой отчёт показал главную точку роста
  ruby-prof через callstack

- как вы решили её оптимизировать
  Отрефакторил создание объектов пользователей.
  ```
  def users_objects_from_users(users, sessions_by_users)
    users.map { |user| User.new(attributes: user, sessions: sessions_by_users[user['id']])  }
  end
  ```

- как изменилась метрика
  На 100000 строк: 1.022015566999471
  На 1000000 строк: 12.545441704998666
  На data_large строк: 55.282536566999624

  На 1М есть прирост, в 4 раза. Теперь точно угадал с главное точкой.
  Первый раз прогнал на data_large. Работаем дальше)

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

  Перестала, более минорные теперь вышли вверх.

### Моя находка №8
- какой отчёт показал главную точку роста

  Точки показывает, но что оптимизировать уже сложно сказать.

- как вы решили её оптимизировать

  Избавился от лишних проходов по массивам, сразу генерируя объекты пользователей.
  Все суммы строк привел к конкатенации
  Подключил оптимизированный json для вывода

- как изменилась метрика
  На 1000000 строк: 11.980859634997614
  На data_large строк: 48.54857596199872

- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  Никак, кажется, что ресурса для автоматизации уже нет.

### Моя находка №9
- какой отчёт показал главную точку роста

  Профилировщики показывают все то же. Но подключение зарядки к ноутбуку показало прирост производительности.

- как вы решили её оптимизировать

  Попробовал запустить текущий код на старенькой домашней персоналке.

- как изменилась метрика
  На data_large строк: ~ 37 секунд. Практически уложился в норматив. Кажется, если взять железо
  еще побыстрее, то в норматив уложусь.

### Моя находка №10
- какой отчёт показал главную точку роста

  ruby-prof через graph
  Озарила мысль, что даты в формате iso8601 можно не парсить для того, чтобы сортировать

- как вы решили её оптимизировать

  Совсем убрал парсинг дат.

- как изменилась метрика
  Теперь уже на слабеньком рабочем ноуте имею 37 секунд на полном объеме.

  На 1000000 строк: 8.811467965002521
  На data_large строк: 37.851983118001954

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с бесконечного времени на нулевом этапе до ~50 секунд на рабочем
ноутбуке и 37 секунд на полноценной персоналке. Считаю, что потенциально в бюджет я уложился.

Для себя сделал следующие выводы:
1) Недооценивал полезность профилировщиков ранее.
2) При использовании профилировщиков важно вовремя подкидывать более большие файлы, когда
на маленьком файле для текущего этапа оптимизации уже погрешность начинает влиять.
3) Возможно, когда оптимизируешь главную точку роста, то стоит заглядывать на побочные. Если их
тоже зацеплять, то показания профилировщика по главной точке будут становится более явными.
4) Очень важно настроить убдобный процесс по тестированию производительности после каждого минимального
улучшения.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я добавил тест, который
написал для 100К строк файла и оставил люфт. Работа теста на этом объеме не большая, должна укладываться
в 1 секунду.
