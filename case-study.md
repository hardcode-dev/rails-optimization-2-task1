# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
*Скорость обработки файла*

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 10-15 секунд

Вот как я построил `feedback_loop`:

Так как измерить скороть обработки файла data_large.txt скриптом без оптимизации выглядит невозможным, было принято решение подготовить несколько
наборов тестовых данных размером в 0.5mb, 1mb, 5mb, 25mb, 60mb и использовать их последовательно, переходя к большему объему тестового файла,
если скрипт обрабатывал объем менее чем за 10 секнунд.

Подготовим файлы подходящего объема
- wc data_large.txt - в файле 3кк строк (134 mb) ~ 30к строк на mb
- head -15000 data_large.txt > data05mb.txt
- head -30000 data_large.txt > data1mb.txt
- head -150000 data_large.txt > data5mb.txt 
- head -750000 data_large.txt > data25mb.txt
- head -1800000 data_large.txt > data60mb.txt

Далее модифицируем скрипт таким образом, чтобы можно было удобно вызывать его, передавая название обрабатываемого файла и выводя время обработки файла.
Каждый раз, запуская обработку файла, запускаем тест и убеждаемся, что программа работает корректно, выводим время обработки файла.

## Вникаем в детали системы, чтобы найти главные точки роста
Попробуем отключить GC, посмотрим, на сколько это повлияет на скорость обработки файла 0.5mb
- запускаем ruby task-1.rb data05mb.txt... processed data05mb.txt in 12.421244000001025 sec
- устанавливаем GC.disable
- запускаем ruby task-1.rb data05mb.txt... processed data05mb.txt in 11.271920999999566 sec
Есть некоторый прирост, но он составляет всего 10-15%. Судя по всему на данном этапе проблемой является вычислительная сложность алгоритма, 
а не потребление памяти. Попробуем найти самые горячие точки и "точки роста". 

### rbspy
Для начала я попробовал исследовать программу при помощи профилировщика rbspy
- sudo rbspy record --pid 55384 

Отчет rbspy не дал какой-то конкретной информации, однако строчка 

- 12.79   100.00  c function - unknown

Может говорить, что большая часть работы производится некой внешней С библиотекой. Продолжим исследование

### ruby-prof
Попробуем исследовать программу при помощи профилировщика ruby-prof в разных режимах

- gem install ruby-prof
- require 'ruby-prof'

### ruby-prof flat - Array#select
Во flat отчете ruby-prof видно, что максимум времени выполнения скрипта занимает функция Array#select
- %self      total      self      wait     child     calls  name                           location
- 89.11     11.330    11.330     0.000     0.000     2288   Array#select

Метод select используется в единственном месте программы, строка 105.
В данный момент это самая горячая точка программы, попробуем ее оптимизировать.
Исходное значение метрики оптимизации - 12 секунд (файл 0.5mb), пробуем внести изменения в код.

Попробуем полностью избавиться от метода select, а парсинг сессий пользователей провести прямо в методе file_lines.each
при первоначальном чтении файла, сразу сохраняя сессиии в user_sessions_hash. 

Время разбора файла размером 0.5mb сократилось до 2-x секунд. Коммитим изменения.

### Ваша находка №X
О вашей находке №X

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
