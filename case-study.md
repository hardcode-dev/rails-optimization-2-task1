# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby 2.4.9`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *время работы скрипта* 

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: *как вы построили feedback_loop*

1) Был с формирован тест про веряющий производительсность работы скрипта на промежутачных объемах файла (2500, 5000, 10000, 20000, 50000, 100000 строк) c ограничение 20 милисекунд на выполнение и фильтаный тест, которые запускает целевой файл и проверяет линейную асимптотику
```
 rspec steps/2_benchmark_sprec.rb
``` 
2) сформирован скрипт для формирования отчетов ruby-prof
```
     ruby steps/3_ruby-prof.rb
```

## Предварительные находки

### Ваша находка №0.1
- в отчете уканано время выполнения `Total: 0.828865`
- обновить ruby с 2.4.9 до 2.7.1
- `Total: 0.786319`

### Ваша находка №0.2
- в отчете уканано время выполнения `Total: 0.786319`
- запустить `rubocop --require rubocop-performance -a`
- `Total: 0.783871` - после трех запусков время +/- не меняется

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался `ruby-prof` на объеме `5000` после ознакомление с отчетами видно `Array#select` выполняется `73.49%` времени время выполнения `Total: 0.783871`

### Ваша находка №1
- отчет `flat` -> `Total: 0.783871` и `Array#select` - `73.49%`
- Подготовить список сессий (предварительно сгруппировать по пользователям)
- отчет `flat` -> `Total: 0.255328` - нет метода - проблем
  запуск `rspec --fail-fast steps/2_benchmark_sprec.rb` показывает, что можно величить объем выборки до '10000'
- на объеме `10000` после ознакомление с отчетами видно `Array#each` выполняется `44.85%` времени время выполнения `Total: 0.559763` 

### Ваша находка №2
- отчет `flat` -> `Total: 0.559763` и `Array#each` - `44.85%`. Метод `each` вызывается в программе 4 раза. Требуется уточное какой из них - проанализирован отчет `callstack` точка роста уточнена до `all?` (`19.77% (28.60%) Array#all?`)
- Оптимизируем подготовку списка уникальный браузеров 
- отчет `flat` -> `Total: 0.451782` - нет метода - проблем
  запуск `rspec --fail-fast steps/2_benchmark_sprec.rb` - размер выборки оставляем прежний 
- на объеме `10000` после ознакомление с отчетами видно `Array#each` выполняется `55.96%` времени время выполнения `Total: 0.451782` 

### Ваша находка №3
- отчет `flat` -> `Total: 0.559763` и `Array#each` - `55.96%`. Метод `each` вызывается в программе 3 раза. Требуется уточное какой из них - проанализирован отчет `callstack` точка роста уточнена до `collect_stats_from_users` (`32.42% (32.42%) Object#collect_stats_from_users [7 calls, 7 total]`)
- решение уменьшиеть количество вызовов `collect_stats_from_users` через изменение передаваемого блока (хренение общей информации для расчетов, уменьшение количество `map`)
- время выполения уменьшилось отчет `flat` -> `Total: 0.414972` и `Array#each` - `56.13%` -> `26.77% (26.77%) Object#collect_stats_from_users [1 calls, 1 total]`
  запуск `rspec --fail-fast steps/2_benchmark_sprec.rb` - размер выборки оставляем прежний 
- на объеме `10000` - большое время выполнения `Date#parse 14.35% (72.87%)`

### Ваша находка №4
- `Date#parse 14.35% (72.87%)` - `parse` так как формат даты определен как, то можно заменить на `Date.iso8601`
- время выполения уменьшилось отчет `flat` -> `Total: 0.360092`
  запуск `rspec --fail-fast steps/2_benchmark_sprec.rb` - размер выборки оставляем прежний 

### Ваша находка №5
- следующий метод для оптимизации - `String#split` - `11.60%`
- методы `parse_user` и `parse_session` - производят повторный парсинг строки - можно передавать уже готовые данные
- время выполения уменьшилось отчет `flat` -> `Total: 0.349431`
  запуск `rspec --fail-fast steps/2_benchmark_sprec.rb` - размер выборки оставляем прежний 

### Ваша находка №6
- отчет `flat` -> `Total: 0.559763` и `Array#each` - `59.89%`. 
- рефакториг цикла (работа на ошибками - это надо было сделать раньше) 
- `rspec --fail-fast steps/2_benchmark_sprec.rb` -> `expected block to perform under 30 sec, but performed above 30.1 sec (± 1.76 sec)`

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с очень долгого до 30 секунд и уложиться в заданный бюджет.

###Доп.выводы:
- Предварительный рефакторинг с экономил бы время и раньше.
- Сортировка даты, как строки в формате `iso8601`

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы `steps/2_benchmark_sprec.rb`

