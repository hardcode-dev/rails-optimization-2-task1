# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
- общее время обработки файла из 500 строк снижается

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`:
- взял файл размером 1000 строк
- написал скрипт который гоняет Benchmark.bmbm c выключеным GC
- там же добавил запуск тогоже объёма с профайлером

## Вникаем в детали системы, чтобы найти главные точки роста
Первое наблюдение:
- файл сначала считывается в память, а потом одной большой строкой сплитится чтобы разделить на строки
- коллекции перебирается 7 раз одинаковым образом


Для того, чтобы найти "точки роста" для оптимизации я воспользовался rbsy, stackprof, ruby-prof, benchmark.
Объединил методы файла в класс Parser и сделал клона ParserOptimized который я буду оптимизировать и сравнивать через Benchmark.bmbm с оригинальным кодом.


Вот какие проблемы удалось найти и решить

### Ваша находка №1
- ruby-prof (graph-html) показал, что метод `collect_stats_from_users` вызывается 7 раз и занимает 37.63% времени. Половину от короторого (16.74%) занимает `Date#parse`. Начнём с него
- Заменю на `Date#strptime` и укажу формат даты для парсера. Так он работает быстрее.
- Среднее время обработки файла в 500 строк снизилось примерно на 20%.
- Отчёт профилировщика показал что на парсинг стало уходить значительно меньше времени, но теперь стало видно что `Array#all?` вызывается 500 раз занимает примерно 20% общего времени

### Ваша находка №2
- `Array#all?` занимает почти 20% общего времени и был вызван 500 раз. Похоже что самопальный `uniq` для `uniqueBrowsers` делает много лишнего.
- Заменил на uniq
- общее время выполнения уменьшилось примерно на 10%. uniq при этом занимает всего 0.37% общего времени.
- Теперь стало сильнее выпячивать `Array#all?` и `Array.select` в подсчёте кол-ва уник браузеров и стате по пользователям.

### Ваша находка №3
- `Array#select` занимает 36% общего времени и самый тяжелый кажется тот что в поиске сессий юзера, потому что для каждого юзера пробегается по всему набору сессий.
- Сделаю сначала группировку через group_by, а потом буду просто по хэшу обращаться
- Общее время уменьшилось примерно на 35%! Круто, но в целом ожидаемо.
- 

### Ваша находка №4
- `Array#map` занимает 36% общего времени. Оно и понятно много лишних пробегов.
- Уберу цепочки `map {}.map {}` там где возможно. Объединить все вызовы collect_stats_from_users в один (-7 итераци:))
- Прирост не значительный, примерно 5-10%.
- Кажется я упёрся в `Array#split` и `Date#strptime`.

### Ваша находка №5
- всё тот же ruby-prof пока справляется с задаче и говорит что `Array#split` занимает 18% времени
- split сложно исключить везде, но в ruby 2.6 появился `split(..) {}` а это значит, что можно с пользой занять эту итерацию и перенести в неё парсинг строк. Плюс убрать лишнюю разбивку в `parse_user` и `parse_session` 
- Прирост незначительный... захожу в тупик
- Кажется что отчёт не сильно поменялся. Откатывать не буду, потому что на бОльших объёмах это будут лишние итерации.

### Ваша находка №6
- теперь видно что `#collect_stats_from_users` в котором почти вся стата 
- split сложно исключить везде, но в ruby 2.6 появился `split(..) {}` а это значит, что можно с пользой занять эту итерацию и перенести в неё парсинг строк. Плюс убрать лишнюю разбивку в `parse_user` и `parse_session` 
- Прирост незначительный... захожу в тупик
- теперь видно что `#collect_stats_from_users` в котором почти вся стата 

### Ваша находка №7
- Решил попробовать CallStack. Удобнее. Показывает примерно около 5-10% съедает парсинг дат. Не самый большой процент, но на больших объёмах может значительно вырасти.
- Так как парсинг даты дорогой, а даты могу повторяться, решил просто кэшировать распарсеные даты. Также сразу привожу к iso8601. Это используется только в обном месте, поэтому кажется самое то.
- Прирост примерно 5%, а `strptime` стал занимать всего 3.7% вместо 9! 
- 14.82% (25.55%) String#split [1000 calls, 1000 total] Что с ним сделать пока не придумал.

### Ваша находка №8
- CallStack. Очень много неявных созданий новых массивов и конкатенаций например для добавления одного объекта в массив используется `array + [item]`. Простая проверка в benchmark показала просто космическую разницу 
- Заменю на `<<` и уберу конкатенацию массивов 
- Прирост примерно примерно 5-10%. Общее время обработки файла ~23 секунды (без GC)! 28-30сек с включеным GC. Успех, Но можно и быстрее... 
- Примерно 30% отнимает чтение файла. Тут вроде вариантов ускорить не осталось. `#collect_stats_from_users` возможно ещё удастся ускорить, но серьёзных успехов там ждать не стоит, потому как большую часть времени просто один #each.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы для обработки 10000 строк с *2.522408* в ~57 раз и уложиться в заданный бюджет.  

### Benchmark.bmbm:
| user      | system   | total    | real                  |
| --------- | -------- | -------- | --------------------- |
| work      | 2.379533 | 0.142875 | 2.522408 (2.557973) |
| optimized | 0.042425 | 0.001911 | 0.044336 (0.045251) |

### Benchmark.ips:
| version   | -------------------- | ----------------------- |
| --------- | -------------------- | ----------------------- |
| work      | 0.400  (± 0.0%) i/s  | 4.000  in  10.134321s   |
| optimized | 22.883  (± 4.4%) i/s | 228.000  in  10.012117s |

optimized:       22.9 i/s  
work:            0.4 i/s - 57.16x  slower  


## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы написал простой rspec тест.

